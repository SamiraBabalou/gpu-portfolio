{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0840f1b9",
   "metadata": {},
   "source": [
    "# GPU Vector Addition with CuPy\n",
    "\n",
    "**Author:** Samira Babalou  \n",
    "**Repository:** gpu-portfolio\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the performance difference between CPU and GPU\n",
    "execution for a simple vector addition operation.\n",
    "\n",
    "The same mathematical operation is executed using:\n",
    "- **NumPy** on the CPU\n",
    "- **CuPy** on the GPU (when available)\n",
    "\n",
    "The goal is to showcase how GPUs accelerate data-parallel workloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ff92d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected: CuPy is available\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports and environment check\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    gpu_available = True\n",
    "    print(\"GPU detected: CuPy is available\")\n",
    "except ImportError:\n",
    "    gpu_available = False\n",
    "    print(\"GPU not available: running CPU-only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3518ce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.042999 seconds\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# CPU vector addition (NumPy)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "N = 10_000_000\n",
    "\n",
    "a_cpu = np.random.rand(N)\n",
    "b_cpu = np.random.rand(N)\n",
    "\n",
    "start_cpu = time.time()\n",
    "c_cpu = a_cpu + b_cpu\n",
    "end_cpu = time.time()\n",
    "\n",
    "cpu_time = end_cpu - start_cpu\n",
    "print(f\"CPU time: {cpu_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ee2a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU time: 0.174469 seconds\n",
      "Speedup: 0.25x\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# GPU vector addition (CuPy)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "if gpu_available:\n",
    "    a_gpu = cp.random.rand(N)\n",
    "    b_gpu = cp.random.rand(N)\n",
    "\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    start_gpu = time.time()\n",
    "\n",
    "    c_gpu = a_gpu + b_gpu\n",
    "\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    end_gpu = time.time()\n",
    "\n",
    "    gpu_time = end_gpu - start_gpu\n",
    "    print(f\"GPU time: {gpu_time:.6f} seconds\")\n",
    "    print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "else:\n",
    "    print(\"Skipping GPU computation (no GPU available).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453a8c9",
   "metadata": {},
   "source": [
    "## Performance Interpretation\n",
    "\n",
    "On this system, GPU execution is available but does not outperform the CPU\n",
    "for the tested vector sizes.\n",
    "\n",
    "This behavior is expected for relatively small or memory-bound workloads,\n",
    "where GPU kernel launch overhead and hostâ€“device memory transfers dominate\n",
    "the total execution time.\n",
    "\n",
    "On a sufficiently large problem size and on a dedicated GPU-enabled system,\n",
    "GPU acceleration typically provides significant speedup once the computational\n",
    "workload exceeds these overheads.\n",
    "\n",
    "This experiment demonstrates an important performance principle:\n",
    "GPU acceleration benefits appear when workload size is large enough to\n",
    "amortize launch and data transfer costs, which is critical when designing\n",
    "GPU-accelerated applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
